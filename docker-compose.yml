services:
  # ================================================================================== #
  # ================================================================================== #
  #                                                                                    #
  #                                    Prelude:                                        #
  #                                                                                    #
  # ================================================================================== #
  #  This compose breaks down data portal deployment into three phased steps such that #
  #  teams can systematically verify requirements and user workflows while minimizing  #
  #  technical overhead. The conductor service below manages all deployments using     #
  #  scripts to automate general setup and configuration.                              #
  # ================================================================================== #
  conductor:
    profiles:
      [
        "phase1",
        "phase2",
        "phase3",
        "stageDev",
        "clean",
        "platform",
        "loadLectern",
        "loadSongSchema",
        "createStudy",
        "loadSongData"
      ]
    image: alpine/curl:8.8.0
    container_name: conductor
    ports:
      - "9204:9204"
    volumes:
      - ./configs/elasticsearchConfigs/file_data_index_template.json:/usr/share/elasticsearch/file_data_index_template.json
      - ./configs/elasticsearchConfigs/tabular_data_index_template.json:/usr/share/elasticsearch/tabular_data_index_template.json
      - ./configs/lecternSchema/lecternSchema.json:/usr/share/lecternSchema/lecternSchema.json
      - ./configs/songSchema/songSchema.json:/usr/share/songSchema/songSchema.json
      - ./data/analysisFile.json:/usr/share/data/analysisFile.json
      - ./scripts:/scripts
      - ./volumes/health:/health
    environment:
      PROFILE: ${PROFILE:-platform}
      DEBUG: false
      # Arranger service script variables
      ARRANGER_FILE_DATA_URL: http://arranger-file:5050/graphql
      ARRANGER_TABULAR_DATA_URL: http://arranger-tabular:5051/graphql
      # Elasticsearch service script variables
      ES_URL: http://elasticsearch:9200
      ES_USER: elastic
      ES_PASS: myelasticpassword
      FILE_INDEX_NAME: file-index
      FILE_ES_TEMPLATE_FILE: /usr/share/elasticsearch/file_data_index_template.json
      FILE_ES_TEMPLATE_NAME: file_template
      FILE_ES_ALIAS_NAME: file_centric
      TABULAR_INDEX_NAME: tabular-index
      TABULAR_ES_TEMPLATE_FILE: /usr/share/elasticsearch/tabular_data_index_template.json
      TABULAR_ES_TEMPLATE_NAME: tabular_template
      TABULAR_ES_ALIAS_NAME: tabular_centric
      # Stage service script variable
      STAGE_URL: http://stage:3000
      # phase2 healthcheck endpoints
      LYRIC_URL: http://lyric:3030
      LECTERN_URL: http://lectern:3031
      LECTERN_SCHEMA: /usr/share/lecternSchema/lecternSchema.json
      # phase3 healthcheck endpoints
      SONG_URL: http://song:8080
      STUDY_ID: demo
      SONG_SCHEMA: /usr/share/songSchema/songSchema.json
      ANALYSIS_FILE: /usr/share/data/analysisFile.json
      SCORE_URL: http://score:8087
      OBJECT_STORAGE_URL: http://minio:9000
      MAESTRO_FILE_URL: http://maestro-file:11235/
      MAESTRO_TABULAR_URL: http://maestro-tabular:11235/
    command: >
      sh -c '
        set -e
          echo "Profile is set to: $PROFILE"
          case "$PROFILE" in
            "phase1")
              echo "Running phase1 deployment..."
              chmod +x scripts/deployments/phase1.sh
              scripts/deployments/phase1.sh
              ;;
            "phase2")
              echo "Running phase2 deployment..."
              chmod +x scripts/deployments/phase2.sh
              scripts/deployments/phase2.sh
              ;;
            "phase3")
              echo "Running phase3 deployment ..."
              chmod +x scripts/deployments/phase3.sh
              scripts/deployments/phase3.sh
              ;;
            "stageDev")
              echo "Running Stage Dev deployment..."
              chmod +x scripts/deployments/stageDev.sh
              scripts/deployments/stageDev.sh
              ;;
            "loadLectern")
              echo "Updating Lectern dictionary..."
              chmod +x scripts/services/phase2/lecternSchemaUpload.sh
              scripts/services/phase2/lecternSchemaUpload.sh
              ;;
            "createStudy")
              echo "Updating Song with a StudyId..."
              chmod +x scripts/services/phase3/songStudyCreation.sh
              scripts/services/phase3/songStudyCreation.sh
              ;;
            "loadSongSchema")
              echo "Updating Songs Schema..."
              chmod +x scripts/services/phase3/songSchemaUpload.sh
              scripts/services/phase3/songSchemaUpload.sh
              ;;
            "loadSongData")
              echo "Loading Song Data..."
              chmod +x scripts/services/phase3/songDataUpload.sh
              scripts/services/phase3/songDataUpload.sh
              ;;
            "clean")
              echo "Removing data..."
              chmod +x scripts/services/phase1/clearElasticsearchData.sh
              scripts/services/phase1/clearElasticsearchData.sh
              ;;
            *)
              echo "No profile set..."
              ;;
          esac
          exit 0
      '
    healthcheck:
      test: ["CMD", "test", "-f", "/health/conductor_health"]
      interval: 5s
      timeout: 40s
      retries: 100
      start_period: 30s
    networks:
      - conductor-network

  # ================================================================================== #
  # ================================================================================== #
  #                                    phase1:                                       #
  #                               Search & Discovery                                   #
  # ================================================================================== #
  # phase1 focuses on how you want your data displayed in the front-end portal.      #
  # Here you want to figure out how many data tables (Arrangers) you want and how you  #
  # want them configured. This is also a good time to do any theming of your portal.   #
  # through Stage.                                                                     #
  # ================================================================================== #

  # ------------------------------------------------------------------------------------#
  # CSV-Processor                                                                       #
  # ------------------------------------------------------------------------------------#
  # Tool for processing and uploading CSV files to Elasticsearch                        #
  # Documentation can be found from ./apps/readme.md & ./docs/phase1.md               #
  # ------------------------------------------------------------------------------------#
  csv-processor:
    profiles: ["data", "config", "all", "platform"]
    image: node:18-alpine
    container_name: data-loader
    ports:
      - "9205:9205"
    volumes:
      - ./apps/csv-processor:/csv-processor
      - ./data:/data
      - ./configs/arrangerConfigs/tabularDataConfigs:/arrangerConfigs/tabularDataConfigs
      - ./configs/elasticsearchConfigs:/elasticsearchConfigs/
      - ./scripts:/scripts
    environment:
      PROFILE: ${PROFILE:-data}
      # Common variables
      TABULAR_DATA_FILE: /data/tabularData.csv
      TABULAR_INDEX_NAME: tabular-index
      ES_URL: http://elasticsearch:9200
      # Config directories
      ES_CONFIG_DIR: /elasticsearchConfigs/tabular_data_index_template.json
      ARRANGER_CONFIG_DIR: /arrangerConfigs/tabularDataConfigs
    command: >
      sh -c '
        case "$PROFILE" in
          "data")
            echo "Running tabular data submission..."
            chmod +x scripts/services/phase1/dataSubmission.sh
            scripts/services/phase1/dataSubmission.sh
            ;;
          "config")
            echo "Generating configurations..."
            chmod +x scripts/services/phase1/generateConfigs.sh
            scripts/services/phase1/generateConfigs.sh
            ;;
          "all")
            echo "Generating configurations..."
            chmod +x scripts/services/phase1/generateConfigs.sh
            scripts/services/phase1/generateConfigs.sh
            echo "Running tabular data submission..."
            chmod +x scripts/services/phase1/dataSubmission.sh
            scripts/services/phase1/dataSubmission.sh
            ;;
          *)
            echo "Invalid profile specified"
            exit 1
            ;;
        esac
        exit 0
       '
    networks:
      - conductor-network

  # --------------------------------------------------------------------------------------#
  # Elasticsearch                                                                         #
  # --------------------------------------------------------------------------------------#
  # A search and analytics engine used to help query massive datasets.                    #
  # Documentation Link:                                                                   #
  # https://www.elastic.co/guide/en/elasticsearch/reference/7.17/elasticsearch-intro.html #
  # --------------------------------------------------------------------------------------#
  elasticsearch:
    profiles: ["phase1", "phase2", "phase3", "stageDev", "platform"]
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.27
    container_name: elasticsearch
    platform: linux/amd64
    ports:
      - "9200:9200"
    environment:
      discovery.type: single-node
      cluster.name: workflow.elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx2048m
      ES_USER: elastic
      ELASTIC_PASSWORD: myelasticpassword
      xpack.security.enabled: "true"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    healthcheck:
      test:
        "curl --silent --fail localhost:9200/_cluster/health?wait_for_status=yellow&timeout=50s ||
        exit 1"
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 25s
    networks:
      - conductor-network

  # ------------------------------------------------------------------------------------#
  # Arranger-Server for our file data                                                   #
  # ------------------------------------------------------------------------------------#
  # Search API generation with compatible search UI components                          #
  # Documentation Link: https://docs.overture.bio/docs/core-software/Arranger/overview  #
  # ------------------------------------------------------------------------------------#
  arranger-file:
    profiles: ["phase1", "phase2", "phase3", "stageDev", "platform"]
    image: ghcr.io/overture-stack/arranger-server:3.0.0-beta.36
    container_name: arranger-file
    platform: linux/amd64
    depends_on:
      conductor:
        condition: service_healthy
    ports:
      - "5050:5050"
    volumes:
      - ./configs/arrangerConfigs/fileDataConfigs/base.json:/app/modules/server/configs/base.json
      - ./configs/arrangerConfigs/fileDataConfigs/extended.json:/app/modules/server/configs/extended.json
      - ./configs/arrangerConfigs/fileDataConfigs/facets.json:/app/modules/server/configs/facets.json
      - ./configs/arrangerConfigs/fileDataConfigs/matchbox.json:/app/modules/server/configs/matchbox.json
      - ./configs/arrangerConfigs/fileDataConfigs/table.json:/app/modules/server/configs/table.json
    environment:
      # Elasticsearch Variables
      ES_HOST: http://elasticsearch:9200
      ES_USER: elastic
      ES_PASS: myelasticpassword
      ES_ARRANGER_SET_INDEX: file_arranger_set
      # Arranger Variables
      DEBUG: false
      ENABLE_LOGS: false
    networks:
      - conductor-network

  # ------------------------------------------------------------------------------------#
  # Arranger-Server for our tabular data                                                #
  # ------------------------------------------------------------------------------------#
  # Search API generation with compatible search UI components                          #
  # Documentation Link: https://docs.overture.bio/docs/core-software/Arranger/overview  #
  # ------------------------------------------------------------------------------------#
  arranger-tabular:
    profiles: ["phase1", "phase2", "phase3", "stageDev", "platform"]
    image: ghcr.io/overture-stack/arranger-server:3.0.0-beta.36
    container_name: arranger-tabular
    platform: linux/amd64
    depends_on:
      conductor:
        condition: service_healthy
    ports:
      - "5051:5051"
    volumes:
      - ./configs/arrangerConfigs/tabularDataConfigs/base.json:/app/modules/server/configs/base.json
      - ./configs/arrangerConfigs/tabularDataConfigs/extended.json:/app/modules/server/configs/extended.json
      - ./configs/arrangerConfigs/tabularDataConfigs/facets.json:/app/modules/server/configs/facets.json
      - ./configs/arrangerConfigs/tabularDataConfigs/matchbox.json:/app/modules/server/configs/matchbox.json
      - ./configs/arrangerConfigs/tabularDataConfigs/table.json:/app/modules/server/configs/table.json
    environment:
      # Elasticsearch Variables
      ES_HOST: http://elasticsearch:9200
      ES_USER: elastic
      ES_PASS: myelasticpassword
      ES_ARRANGER_SET_INDEX: tabular_arranger_set
      # Arranger Variables (Port required)
      PORT: 5051
      DEBUG: false
      ENABLE_LOGS: false
    networks:
      - conductor-network

  # ------------------------------------------------------------------------------------#
  # Stage                                                                               #
  # ------------------------------------------------------------------------------------#
  # The react-based, front end UI scaffolding for Overture                              #
  # Documentation Link: https://docs.overture.bio/docs/core-software/Stage/overview     #
  # ------------------------------------------------------------------------------------#
  stage:
    profiles: ["phase1", "phase2", "phase3", "platform"]
    image: localstageimage:1.0
    container_name: stage
    pull_policy: never
    platform: linux/arm64/v8
    depends_on:
      conductor:
        condition: service_healthy
    ports:
      - "3000:3000"
    environment:
      # Stage Variables
      NEXTAUTH_URL: http://localhost:3000/api/auth
      NEXT_PUBLIC_LAB_NAME: Overture Prelude Portal
      NEXT_PUBLIC_ADMIN_EMAIL: example@example.com
      NEXT_PUBLIC_DEBUG: false
      NEXT_PUBLIC_SHOW_MOBILE_WARNING: true
      NEXT_PUBLIC_ENABLE_DOWNLOADS: true
      # File Arranger Variables
      NEXT_PUBLIC_ARRANGER_FILE_DATA_API: http://arranger-file:5050
      NEXT_PUBLIC_ARRANGER_FILE_DATA_DOCUMENT_TYPE: file
      NEXT_PUBLIC_ARRANGER_FILE_DATA_INDEX: file_centric
      NEXT_PUBLIC_ARRANGER_MANIFEST_COLUMNS: repositories.code, analysis.analysis_id, object_id, study_id, file.name, file.size, file.md5sum, file_access, analysis.experiment.acknowledgements.strategy, file.data_type, analysis.experiment.data.sequence_length
      # Tabular Arranger Variables
      NEXT_PUBLIC_ARRANGER_TABULAR_DATA_API: http://arranger-tabular:5051
      NEXT_PUBLIC_ARRANGER_TABULAR_DATA_DOCUMENT_TYPE: file
      NEXT_PUBLIC_ARRANGER_TABULAR_DATA_INDEX: tabular_centric
      # Using localhost for client-side requests
      NEXT_PUBLIC_SONG_API: http://song:8080
      NEXT_PUBLIC_LYRIC_API: http://lyric:3030
      NEXT_PUBLIC_LECTERN_API: http://lectern:3031
      NEXT_PUBLIC_SCORE_API: http://score:8087
      # Auth Variables
      NEXTAUTH_SECRET: your-secure-secret-here
      # System Alerts
      # NEXT_PUBLIC_SYSTEM_ALERTS: '[{"level":"info","title":"API Documentation Available","message":"Swagger documentation for Song, Lyric, Lectern, and Score APIs is now available in the Documentation section.","dismissable":true,"id":"api-docs-available"}]'
      # CORS Configuration
      NEXT_PUBLIC_CORS_ENABLED: "true"
      NEXT_PUBLIC_CORS_ALLOWED_ORIGINS: "*"
    volumes:
      - stage-data:/usr/src/public/static/dms_user_assets
    networks:
      - conductor-network

  # ================================================================================== #
  # ================================================================================== #
  #                                    phase2:                                         #
  #                          Tabular data storage & submission                         #
  # ================================================================================== #
  # Here we will focus on implementing our back-end tabular data management services   #
  # which will include the addition of Lyric, Lectern, LyricDb (Postgres) and a        #
  # LecternDb (MongoDb).                                                               #
  # ================================================================================== #

  # -----------------------------------------------------------------------------------#
  # Lectern                                                                            #
  # -----------------------------------------------------------------------------------#
  # Schema manager that validates and stores collections of data dictionaries.         #
  # Documentation Link: https://docs.overture.bio/docs/under-development/lectern/      #
  # -----------------------------------------------------------------------------------#
  lectern:
    profiles: ["phase2", "phase3", "platform"]
    image: ghcr.io/overture-stack/lectern:2.0.0-beta.3
    container_name: lectern
    platform: linux/amd64
    depends_on:
      lectern-db:
        condition: service_healthy
    ports:
      - "3031:3031"
    environment:
      PORT: 3031
      OPENAPI_PATH: /api-docs
      MONGO_HOST: lectern-db
      MONGO_PORT: 27017
      MONGO_DB: lectern
      MONGO_USER: admin
      MONGO_PASS: admin123
      AUTH_ENABLED: false
      VAULT_ENABLED: false
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # LecternDb                                                                          #
  # -----------------------------------------------------------------------------------#
  # Database used by Lectern to store its schemas.                                     #
  # -----------------------------------------------------------------------------------#
  lectern-db:
    profiles: ["phase2", "phase3", "platform"]
    image: bitnami/mongodb:4.0
    container_name: lectern-db
    platform: linux/amd64
    ports:
      - 27017:27017
    volumes:
      - lectern-db-data:/bitnami
    environment:
      MONGODB_USERNAME: admin
      MONGODB_PASSWORD: admin123
      MONGODB_DATABASE: lectern
      MONGODB_ROOT_PASSWORD: admin123
    healthcheck:
      test:
        [
          "CMD",
          "mongo",
          "--authenticationDatabase",
          "admin",
          "-u",
          "root",
          "-p",
          "admin123",
          "--eval",
          "db.adminCommand('ping')"
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # Lryic                                                                              #
  # -----------------------------------------------------------------------------------#
  # Submit, validate, and manage structured data according to predefined schemas.      #
  # Documentation Link: https://docs.overture.bio/docs/under-development/lyric/        #
  # -----------------------------------------------------------------------------------#
  lyric:
    profiles: ["phase2", "phase3", "platform"]
    image: ghcr.io/overture-stack/lyric:0.6.0
    container_name: lyric
    platform: linux/amd64
    depends_on:
      lyric-db:
        condition: service_healthy
      lectern:
        condition: service_started
    ports:
      - "3030:3030"
    environment:
      PORT: 3030
      DB_HOST: lyric-db
      DB_PORT: 5432
      DB_NAME: lyricDb
      DB_USER: admin
      DB_PASSWORD: admin123
      LECTERN_URL: http://lectern:3001
      LOG_LEVEL: info
      AUDIT_ENABLED: false
      ID_USELOCAL: true
      UPLOAD_LIMIT: "100mb"
      PLURALIZE_SCHEMAS_ENABLED: false
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # LyricDb                                                                            #
  # -----------------------------------------------------------------------------------#
  # Database used by Lyric to store its tabular data.                                  #                                                               #
  # -----------------------------------------------------------------------------------#
  lyric-db:
    profiles: ["phase2", phase3, "platform"]
    image: postgres:15-alpine
    container_name: lyric-db
    platform: linux/amd64
    ports:
      - 5434:5432
    environment:
      POSTGRES_PASSWORD: admin123
      POSTGRES_USER: admin
      POSTGRES_DB: lyricDb
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d lyricDb"]
      interval: 20s
      timeout: 10s
      retries: 10
      start_period: 20s
    volumes:
      - lyric-db-data:/var/lib/postgresql/data
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # Maestro (Tabular Data)                                                             #
  # -----------------------------------------------------------------------------------#
  # Indexs tabular data into Elasticsearch on publication                              #
  # Documentation Link: https://docs.overture.bio/docs/core-software/Maestro/overview  #
  # -----------------------------------------------------------------------------------#
  maestro-tabular:
    profiles: ["phase2", phase3, "platform"]
    image: ghcr.io/overture-stack/maestro:4.3.0
    container_name: maestro-tabular
    platform: linux/amd64
    depends_on:
      lectern:
        condition: service_started
      conductor:
        condition: service_healthy
    ports:
      - "11236:11235"
    environment:
      # Maestro Variables
      MAESTRO_FAILURELOG_ENABLED: true
      MAESTRO_FAILURELOG_DIR: app/logs/maestro
      MAESTRO_LOGGING_LEVEL_ROOT: INFO
      MAESTRO_NOTIFICATIONS_SLACK_ENABLED: false
      MAESTRO_DISABLEEVENTINDEXING: true
      # Song Variables
      MAESTRO_REPOSITORIES_0_CODE: song.overture
      MAESTRO_REPOSITORIES_0_URL: http://song:8080
      MAESTRO_REPOSITORIES_0_NAME: Overture
      MAESTRO_REPOSITORIES_0_ORGANIZATION: OICR
      MAESTRO_REPOSITORIES_0_COUNTRY: CA
      # Elasticsearch Variables
      MAESTRO_ELASTICSEARCH_CLUSTER_NODES: http://elasticsearch:9200
      MAESTRO_ELASTICSEARCH_CLIENT_BASICAUTH_USER: elastic
      MAESTRO_ELASTICSEARCH_CLIENT_BASICAUTH_PASSWORD: myelasticpassword
      MAESTRO_ELASTICSEARCH_CLIENT_TRUSTSELFSIGNCERT: true
      MAESTRO_ELASTICSEARCH_INDEXES_ANALYSISCENTRIC_ENABLED: false
      MAESTRO_ELASTICSEARCH_INDEXES_FILECENTRIC_ENABLED: true
      MAESTRO_ELASTICSEARCH_INDEXES_FILECENTRIC_NAME: tabular-index
      MAESTRO_ELASTICSEARCH_INDEXES_FILECENTRIC_ALIAS: tabular_centric
      MAESTRO_ELASTICSEARCH_CLIENT_BASICAUTH_ENABLED: true
      MANAGEMENT_HEALTH_ELASTICSEARCH_ENABLED: false
      # Spring Variables
      SPRING_MVC_ASYNC_REQUESTTIMEOUT: -1
      SPRINGDOC_SWAGGERUI_PATH: /swagger-api
    volumes:
      - maestro-file-data:/app/app-data
    networks:
      - conductor-network

  # ================================================================================== #
  # ================================================================================== #
  #                                    phase3:                                     #
  #                          File data storage & submission                            #
  # ================================================================================== #
  # Here we will focus on implementing our back-end file management services which     #
  # will include the addition of Song, Score, SongDb (Postgres) and an Object          #
  # Storage provider (Minio).                                                          #
  # ================================================================================== #

  # -----------------------------------------------------------------------------------#
  # Song                                                                               #
  # -----------------------------------------------------------------------------------#
  # Catalog and manage metadata associated to file data                                #                                                               #
  # Documentation Link: https://docs.overture.bio/docs/core-software/Song/overview     #
  # -----------------------------------------------------------------------------------#
  song:
    profiles: ["phase3", "platform"]
    image: ghcr.io/overture-stack/song-server:a81a8e48
    container_name: song
    platform: linux/amd64
    depends_on:
      song-db:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      # Spring Variables
      SPRING_PROFILES_ACTIVE: dev, noSecurityDev
      # Swagger/OpenAPI Configuration
      SPRING_MVC_CORS_ENABLED: "true"
      SPRING_MVC_CORS_ALLOWED-ORIGINS: "*"
      SPRING_MVC_CORS_ALLOWED-METHODS: "GET,POST,PUT,DELETE,PATCH,OPTIONS"
      SPRING_MVC_CORS_ALLOWED-HEADERS: "*"
      SPRING_MVC_CORS_ALLOW-CREDENTIALS: "true"
      # Flyway variables
      SPRING_FLYWAY_ENABLED: true
      # Song Variables
      ID_USELOCAL: true
      SCHEMAS_ENFORCELATEST: true
      # Score Variables
      SCORE_URL: http://score:8087
      # Postgres Variables
      SPRING_DATASOURCE_URL: jdbc:postgresql://song-db:5432/songDb?stringtype=unspecified
      SPRING_DATASOURCE_USERNAME: admin
      SPRING_DATASOURCE_PASSWORD: admin123
      # Swagger Variable
      SWAGGER_ALTERNATEURL: /swagger-api
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # SongDb                                                                             #
  # -----------------------------------------------------------------------------------#
  # Database used by Lyric to store its tabular data.                                  #                                                               #
  # -----------------------------------------------------------------------------------#
  song-db:
    profiles: ["phase3", "platform"]
    depends_on:
      - conductor
    image: postgres:11.1
    container_name: song-db
    platform: linux/amd64
    ports:
      - "5433:5432"
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin123
      POSTGRES_DB: songDb
    user: postgres:postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d songDb"]
      interval: 20s
      timeout: 10s
      retries: 10
      start_period: 20s
    volumes:
      - song-db-data:/var/lib/postgresql/data
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # Score                                                                              #
  # -----------------------------------------------------------------------------------#
  # Transfer file data to and from any S3 object storage.                              #
  # Documentation Link: https://docs.overture.bio/docs/core-software/Score/overview    #                                                            #
  # -----------------------------------------------------------------------------------#
  score:
    profiles: ["phase3", "platform"]
    image: ghcr.io/overture-stack/score-server:6c4a3a3c
    container_name: score
    platform: linux/amd64
    depends_on:
      minio:
        condition: service_healthy
    ports:
      - "8087:8087"
    environment:
      # Spring Variables
      SPRING_PROFILES_ACTIVE: noSecurityDev, s3
      SERVER_PORT: 8087
      # Song Variable
      METADATA_URL: http://song:8080
      # Score Variables
      SERVER_SSL_ENABLED: "false"
      # Object Storage Variables
      S3_ENDPOINT: http://host.docker.internal:9000
      S3_ACCESSKEY: admin
      S3_SECRETKEY: admin123
      S3_SIGV4ENABLED: true
      S3_SECURED: false
      OBJECT_SENTINEL: heliograph
      BUCKET_NAME_OBJECT: object
      BUCKET_NAME_STATE: state
      UPLOAD_PARTSIZE: 1073741824
      UPLOAD_CONNECTION_TIMEOUT: 1200000
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # Minio                                                                              #
  # -----------------------------------------------------------------------------------#
  # A locally deployed open source S3-compatible object storage                        #
  # Documentation Link:                                                                #
  # http://docs.overture.bio/guides/deployment-guide/data-management-&-storage         #
  # -----------------------------------------------------------------------------------#
  minio:
    profiles: ["phase3", "platform"]
    image: minio/minio:RELEASE.2018-05-11T00-29-24Z
    container_name: minio
    platform: linux/amd64
    ports:
      - 9000:9000
    environment:
      MINIO_ACCESS_KEY: admin
      MINIO_SECRET_KEY: admin123
    command: server /data
    volumes:
      - ./volumes/data-minio:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - conductor-network

  # -----------------------------------------------------------------------------------#
  # Maestro (File Data)                                                                #
  # -----------------------------------------------------------------------------------#
  # Indexs file data into Elasticsearch on publication                                 #
  # Documentation Link: https://docs.overture.bio/docs/core-software/Maestro/overview  #
  # -----------------------------------------------------------------------------------#
  maestro-file:
    profiles: ["phase3", "platform"]
    image: ghcr.io/overture-stack/maestro:4.3.0
    container_name: maestro-file
    platform: linux/amd64
    depends_on:
      song:
        condition: service_started
      conductor:
        condition: service_healthy
    ports:
      - "11235:11235"
    environment:
      # Maestro Variables
      MAESTRO_FAILURELOG_ENABLED: true
      MAESTRO_FAILURELOG_DIR: app/logs/maestro
      MAESTRO_LOGGING_LEVEL_ROOT: INFO
      MAESTRO_NOTIFICATIONS_SLACK_ENABLED: false
      MAESTRO_DISABLEEVENTINDEXING: true
      # Song Variables
      MAESTRO_REPOSITORIES_0_CODE: song.overture
      MAESTRO_REPOSITORIES_0_URL: http://song:8080
      MAESTRO_REPOSITORIES_0_NAME: Overture
      MAESTRO_REPOSITORIES_0_ORGANIZATION: OICR
      MAESTRO_REPOSITORIES_0_COUNTRY: CA
      # Elasticsearch Variables
      MAESTRO_ELASTICSEARCH_CLUSTER_NODES: http://elasticsearch:9200
      MAESTRO_ELASTICSEARCH_CLIENT_BASICAUTH_USER: elastic
      MAESTRO_ELASTICSEARCH_CLIENT_BASICAUTH_PASSWORD: myelasticpassword
      MAESTRO_ELASTICSEARCH_CLIENT_TRUSTSELFSIGNCERT: true
      MAESTRO_ELASTICSEARCH_INDEXES_ANALYSISCENTRIC_ENABLED: false
      MAESTRO_ELASTICSEARCH_INDEXES_FILECENTRIC_ENABLED: true
      MAESTRO_ELASTICSEARCH_INDEXES_FILECENTRIC_NAME: file-index
      MAESTRO_ELASTICSEARCH_INDEXES_FILECENTRIC_ALIAS: file_centric
      MAESTRO_ELASTICSEARCH_CLIENT_BASICAUTH_ENABLED: true
      MANAGEMENT_HEALTH_ELASTICSEARCH_ENABLED: false
      # Spring Variables
      SPRING_MVC_ASYNC_REQUESTTIMEOUT: -1
      SPRINGDOC_SWAGGERUI_PATH: /swagger-api
    volumes:
      - maestro-file-data:/app/app-data
    networks:
      - conductor-network

volumes:
  elasticsearch-data:
  stage-data:
  maestro-file-data:
  maestro-tabular-data:
  song-db-data:
  lyric-db-data:
  lectern-db-data:
networks:
  conductor-network:
    driver: bridge
